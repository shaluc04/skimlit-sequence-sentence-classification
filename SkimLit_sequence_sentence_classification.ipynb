{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkimLit_sequence_sentence_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIqEBBVo87P6NvfVZtEDKf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOIPWdpij3-n"
      },
      "source": [
        "# SkimLit\n",
        "\n",
        "> The purpose of this notebook is to build an NLP model to make reading medical abstracts easier.\n",
        "\n",
        "The paper  we're replicating (the source of the dataset we'll be using) is available here: https://arxiv.org/pdf/1710.06071.pdf\n",
        "\n",
        "The model architecture that they use to achieve their best results is available here: https://arxiv.org/pdf/1612.05251.pdf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-b2myNu5CkG"
      },
      "source": [
        "## Confirm access to a GPU\n",
        "# !nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOzj_1mvlEAj"
      },
      "source": [
        "## Get data\n",
        "\n",
        "Since we'll be replicating the paper above (PubMed 200k RCT), let's download the dataset they used.\n",
        "\n",
        "We can do so from the author's Github: https://github.com/Franck-Dernoncourt/pubmed-rct"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnAopyh-lkFn",
        "outputId": "f2aced07-aa23-46f8-921e-502e0bd5049b"
      },
      "source": [
        "!git clone https://github.com/Franck-Dernoncourt/pubmed-rct\n",
        "!ls pubmed-rct"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pubmed-rct'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 33 (delta 0), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (33/33), done.\n",
            "PubMed_200k_RCT\n",
            "PubMed_200k_RCT_numbers_replaced_with_at_sign\n",
            "PubMed_20k_RCT\n",
            "PubMed_20k_RCT_numbers_replaced_with_at_sign\n",
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNa9DYYQmRWl",
        "outputId": "0f66efda-59f2-4a7a-e7a9-77ed58c1cc6f"
      },
      "source": [
        "# check what files are in the Pubmed_20k dataset\n",
        "!ls pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\n",
        "!ls pubmed-rct/PubMed_20k_RCT/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev.txt  test.txt  train.txt\n",
            "dev.txt  test.txt  train.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yASfjq4Km6MC"
      },
      "source": [
        "# start our experiments using the 20k dataset with numbers replaced with @ sign\n",
        "data_dir = \"pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-yrul_-oYnP",
        "outputId": "eb606761-c0ee-41c3-ca87-7632b61d9ec8"
      },
      "source": [
        "# check all of the file names in the target directory\n",
        "import os\n",
        "filenames = [data_dir + filename for filename in os.listdir(data_dir)]\n",
        "filenames"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/train.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/test.txt',\n",
              " 'pubmed-rct/PubMed_20k_RCT_numbers_replaced_with_at_sign/dev.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQnoTcF-pIsh"
      },
      "source": [
        "## Preprocess data\n",
        "\n",
        "Now we've got some text data, let's begin exploring it!\n",
        "\n",
        "Let's write a function to read in all of the lines of a target text file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BX44Un8qH3f"
      },
      "source": [
        "# Create function to read the lines of a document\n",
        "def get_lines(filename):\n",
        "  '''\n",
        "  Reads filename (a text filename) and returns the lines of text as a list.\n",
        "  \n",
        "  Args:\n",
        "    filename: a string containing the target filepath\n",
        "\n",
        "  Returns:\n",
        "    A list of strings with one string per line from the target filename.\n",
        "  '''\n",
        "  with open(filename, \"r\") as f:\n",
        "    return f.readlines()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuYgmON5sHl-",
        "outputId": "471d5988-0f6a-47ce-e425-4779fa972d88"
      },
      "source": [
        "# Let's read in the training lines\n",
        "train_lines = get_lines(data_dir+\"train.txt\") # read the lines in the training file\n",
        "train_lines[:20]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['###24293578\\n',\n",
              " 'OBJECTIVE\\tTo investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\\n',\n",
              " 'METHODS\\tA total of @ patients with primary knee OA were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .\\n',\n",
              " 'METHODS\\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\\n',\n",
              " 'METHODS\\tPain was assessed using the visual analog pain scale ( @-@ mm ) .\\n',\n",
              " 'METHODS\\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and @-min walk distance ( @MWD ) .\\n',\n",
              " 'METHODS\\tSerum levels of interleukin @ ( IL-@ ) , IL-@ , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\\n',\n",
              " 'RESULTS\\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and @MWD at @ weeks .\\n',\n",
              " 'RESULTS\\tThe mean difference between treatment arms ( @ % CI ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .\\n',\n",
              " 'RESULTS\\tFurther , there was a clinically relevant reduction in the serum levels of IL-@ , IL-@ , TNF - , and hsCRP at @ weeks in the intervention group when compared to the placebo group .\\n',\n",
              " 'RESULTS\\tThese differences remained significant at @ weeks .\\n',\n",
              " 'RESULTS\\tThe Outcome Measures in Rheumatology Clinical Trials-Osteoarthritis Research Society International responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .\\n',\n",
              " 'CONCLUSIONS\\tLow-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee OA ( ClinicalTrials.gov identifier NCT@ ) .\\n',\n",
              " '\\n',\n",
              " '###24854809\\n',\n",
              " 'BACKGROUND\\tEmotional eating is associated with overeating and the development of obesity .\\n',\n",
              " 'BACKGROUND\\tYet , empirical evidence for individual ( trait ) differences in emotional eating and cognitive mechanisms that contribute to eating during sad mood remain equivocal .\\n',\n",
              " 'OBJECTIVE\\tThe aim of this study was to test if attention bias for food moderates the effect of self-reported emotional eating during sad mood ( vs neutral mood ) on actual food intake .\\n',\n",
              " 'OBJECTIVE\\tIt was expected that emotional eating is predictive of elevated attention for food and higher food intake after an experimentally induced sad mood and that attentional maintenance on food predicts food intake during a sad versus a neutral mood .\\n',\n",
              " 'METHODS\\tParticipants ( N = @ ) were randomly assigned to one of the two experimental mood induction conditions ( sad/neutral ) .\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UICSMkzfshnq",
        "outputId": "41ab00d1-46a8-400a-ce57-63d6c9700503"
      },
      "source": [
        "len(train_lines)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "210040"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1roI8-Wns6ev"
      },
      "source": [
        "Let's think about how we want our data to look...\n",
        "\n",
        "Example: a list of dictionary....( a list of abstracts containing dictionaries for each line (sentence)).\n",
        "\n",
        "```\n",
        "[{'line_number': 0,\n",
        "   'target': \"BACKGROUND\",\n",
        "   'text': \"Emotional eating is associated with overeating and the development of obesity.\",\n",
        "   'total_lines':11}\n",
        "   ...]\n",
        "```\n",
        "\n",
        "Line number is important as sequence matters. (conclusion cannot come before introduction.)\n",
        "Total lines - number of lines in a given abstract.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CvtIFMmuNAP"
      },
      "source": [
        " def preprocess_text_with_line_numbers(filename):\n",
        "  \"\"\"\n",
        "  Returns a list of dictionaries of abstract line data.\n",
        "\n",
        "  Takes in filename, reads its contents and sorts through each line,\n",
        "  extracting things like the target label, the text of the sentence,\n",
        "  how many sentences are in the current abstract and what sentence\n",
        "  number the target line is.\n",
        "  \"\"\"\n",
        "  input_lines = get_lines(filename) # get all lines from filename\n",
        "  absract_lines = \"\"  # create an empty abstract\n",
        "  abstract_samples = []  # create an empty list of abstracts\n",
        "  \n",
        "  # loop through each line in the target file\n",
        "  for line in input_lines:\n",
        "    if line.startswith(\"###\"):  # check to see if the line is an ID line\n",
        "      abstract_id = line\n",
        "      abstract_lines = \"\" # reset the abstract string if the line is an ID line\n",
        "    elif line.isspace():  # check to see if line is a new line\n",
        "      abstract_line_split = abstract_lines.splitlines()  # split abstract into separate lines\n",
        "\n",
        "      # Iterate through each line in a single abstract and count them at the same time\n",
        "      for abstract_line_number, abstract_line in enumerate(abstract_line_split):\n",
        "        line_data = {} # create an empty dictionary for each line\n",
        "        target_text_split = abstract_line.split(\"\\t\") # split target label from text\n",
        "        line_data[\"target\"] = target_text_split[0] # get target label\n",
        "        line_data[\"text\"] = target_text_split[1].lower()  # get target text and lower it\n",
        "        line_data[\"line_number\"] = abstract_line_number # what number line does the line appear in abstract\n",
        "        line_data[\"total_lines\"] = len(abstract_line_split) - 1 # how many total lines are there in the target abstract? (starts from 0)\n",
        "        abstract_samples.append(line_data)  # add line data to abstract samples list\n",
        "\n",
        "    else: # if the above conditions aren't fulfilled, the line contains a labelled structure\n",
        "        abstract_lines += line\n",
        "  \n",
        "  return abstract_samples"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29rczA0bQyDg",
        "outputId": "b0e9bd1a-dd34-4465-f075-139d39b29e7b"
      },
      "source": [
        "# get data from file and preprocess it\n",
        "%%time\n",
        "train_samples = preprocess_text_with_line_numbers(data_dir + \"train.txt\")\n",
        "val_samples = preprocess_text_with_line_numbers(data_dir+\"dev.txt\")\n",
        "test_samples = preprocess_text_with_line_numbers(data_dir+\"test.txt\")\n",
        "print(len(train_samples), len(val_samples), len(test_samples))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "180040 30212 30135\n",
            "CPU times: user 486 ms, sys: 126 ms, total: 612 ms\n",
            "Wall time: 613 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydw4L7RkRXRC",
        "outputId": "227f4960-3aa2-4e08-89e9-39e5e902764d"
      },
      "source": [
        "# check the first abstract of our training data\n",
        "train_samples[:13]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'line_number': 0,\n",
              "  'target': 'OBJECTIVE',\n",
              "  'text': 'to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 1,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 2,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 3,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 4,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 5,\n",
              "  'target': 'METHODS',\n",
              "  'text': 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 6,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 7,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 8,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 9,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'these differences remained significant at @ weeks .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 10,\n",
              "  'target': 'RESULTS',\n",
              "  'text': 'the outcome measures in rheumatology clinical trials-osteoarthritis research society international responder rate was @ % in the intervention group and @ % in the placebo group ( p < @ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 11,\n",
              "  'target': 'CONCLUSIONS',\n",
              "  'text': 'low-dose oral prednisolone had both a short-term and a longer sustained effect resulting in less knee pain , better physical function , and attenuation of systemic inflammation in older patients with knee oa ( clinicaltrials.gov identifier nct@ ) .',\n",
              "  'total_lines': 11},\n",
              " {'line_number': 0,\n",
              "  'target': 'BACKGROUND',\n",
              "  'text': 'emotional eating is associated with overeating and the development of obesity .',\n",
              "  'total_lines': 10}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcutYyNeYyAb"
      },
      "source": [
        "Now that our data is in the format of a list of dictionaries, how about we turn it into a DataFrame to further visualize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRMm2_NsSbNt"
      },
      "source": [
        "import pandas as pd\n",
        "train_df = pd.DataFrame(train_samples)\n",
        "val_df = pd.DataFrame(val_samples)\n",
        "test_df = pd.DataFrame(test_samples)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "71cZlIToZJCP",
        "outputId": "be5ed12d-f5ed-458f-ca43-51c27b17a734"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>text</th>\n",
              "      <th>line_number</th>\n",
              "      <th>total_lines</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>OBJECTIVE</td>\n",
              "      <td>to investigate the efficacy of @ weeks of dail...</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>a total of @ patients with primary knee oa wer...</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>outcome measures included pain reduction and i...</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>pain was assessed using the visual analog pain...</td>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>METHODS</td>\n",
              "      <td>secondary outcome measures included the wester...</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      target  ... total_lines\n",
              "0  OBJECTIVE  ...          11\n",
              "1    METHODS  ...          11\n",
              "2    METHODS  ...          11\n",
              "3    METHODS  ...          11\n",
              "4    METHODS  ...          11\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pIW-bcAZLX2",
        "outputId": "e969f4f8-da58-4f15-ef6a-bf098af4174e"
      },
      "source": [
        "# check out the distribution of labels\n",
        "train_df[\"target\"].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "METHODS        59353\n",
              "RESULTS        57953\n",
              "CONCLUSIONS    27168\n",
              "BACKGROUND     21727\n",
              "OBJECTIVE      13839\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "77mzKNeqZiMw",
        "outputId": "51e20890-ca88-4cdd-ac5a-a4b03ac96f7c"
      },
      "source": [
        "# let's check the length of different abstracts (number of lines in abstracts)\n",
        "train_df.total_lines.plot.hist();"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUMa3j2AZyMT",
        "outputId": "f83c2436-b618-4c9c-df88-e9446cc29f67"
      },
      "source": [
        "train_df[\"total_lines\"].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11    24468\n",
              "10    23639\n",
              "12    22113\n",
              "9     19400\n",
              "13    18438\n",
              "14    14610\n",
              "8     12285\n",
              "15    10768\n",
              "7      7464\n",
              "16     7429\n",
              "17     5202\n",
              "6      3353\n",
              "18     3344\n",
              "19     2480\n",
              "20     1281\n",
              "5      1146\n",
              "21      770\n",
              "22      759\n",
              "23      264\n",
              "4       215\n",
              "24      200\n",
              "25      182\n",
              "26       81\n",
              "28       58\n",
              "3        32\n",
              "30       31\n",
              "27       28\n",
              "Name: total_lines, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_N3KQLoaVkF"
      },
      "source": [
        "### Get lists of sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfxjdg8fav4K"
      },
      "source": [
        "# Convert abstracts text lines into lists\n",
        "train_sentences = train_df[\"text\"].tolist()\n",
        "val_sentences = val_df[\"text\"].tolist()\n",
        "test_sentences = test_df[\"text\"].tolist()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivxHklr6bCq-",
        "outputId": "911305ab-b054-4a84-c428-661f547ac525"
      },
      "source": [
        "len(train_sentences), len(val_sentences), len(test_sentences)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(180040, 30212, 30135)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3iid7IxbIvB",
        "outputId": "cb537052-fa70-4709-a7fe-137efc2ce03f"
      },
      "source": [
        "# View 10 lines of training sentences\n",
        "train_sentences[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .',\n",
              " 'pain was assessed using the visual analog pain scale ( @-@ mm ) .',\n",
              " 'secondary outcome measures included the western ontario and mcmaster universities osteoarthritis index scores , patient global assessment ( pga ) of the severity of knee oa , and @-min walk distance ( @mwd ) .',\n",
              " 'serum levels of interleukin @ ( il-@ ) , il-@ , tumor necrosis factor ( tnf ) - , and high-sensitivity c-reactive protein ( hscrp ) were measured .',\n",
              " 'there was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , pga , and @mwd at @ weeks .',\n",
              " 'the mean difference between treatment arms ( @ % ci ) was @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; @ ( @-@ @ ) , p < @ ; and @ ( @-@ @ ) , p < @ , respectively .',\n",
              " 'further , there was a clinically relevant reduction in the serum levels of il-@ , il-@ , tnf - , and hscrp at @ weeks in the intervention group when compared to the placebo group .',\n",
              " 'these differences remained significant at @ weeks .']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sud_RADWbQO0"
      },
      "source": [
        "## Make numeric labels (ML models required numeric labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yv65Vs_5Bx1"
      },
      "source": [
        "### One-hot encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XcyzB2V24dV",
        "outputId": "ec3bb851-a999-4237-8061-4b1b1897090a"
      },
      "source": [
        "# One hto encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False) # we want a non-sparse matrix\n",
        "train_labels_one_hot = one_hot_encoder.fit_transform(train_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "val_labels_one_hot = one_hot_encoder.transform(val_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "test_labels_one_hot = one_hot_encoder.transform(test_df[\"target\"].to_numpy().reshape(-1,1))\n",
        "\n",
        "# check what one hot encoded labels look like\n",
        "train_labels_one_hot"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dahj1mBY3fzJ"
      },
      "source": [
        "### Label encode labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UZONqg15H5F"
      },
      "source": [
        "# extract labels (\"target\" columns) and encode them into integers\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels_encoded = label_encoder.fit_transform(train_df[\"target\"].to_numpy())\n",
        "val_labels_encoded = label_encoder.transform(val_df[\"target\"].to_numpy())\n",
        "test_labels_encoded = label_encoder.transform(test_df[\"target\"].to_numpy())"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydYBCV_s5u2O",
        "outputId": "b8d319fc-19ba-4a27-a8d3-63395b4ab9db"
      },
      "source": [
        "# check what training labels look like\n",
        "train_labels_encoded"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 2, 2, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceJQQvVt5z7m",
        "outputId": "e43d8987-7fa8-4a1f-92db-8671ef6b08eb"
      },
      "source": [
        "# get class names and number of classes from LabelEncoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "\n",
        "num_classes, class_names"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4los30WrLZr0"
      },
      "source": [
        "## Modelling experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPBws6gT6YAz"
      },
      "source": [
        "### Model 0: Getting a baseline\n",
        "\n",
        "Let's start modelling with TF-IDF Multinomial Naive Bayes classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdnFZVErLdTt",
        "outputId": "0a6c2a72-5bfc-4bde-fd95-948c1e71b1f0"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "  (\"tf-idf\", TfidfVectorizer()),\n",
        "  (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X=train_sentences,\n",
        "            y=train_labels_encoded)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RODIz1FqMyCf",
        "outputId": "7479a559-25a4-4382-d882-308946e2219f"
      },
      "source": [
        "# Evaluate baseline model on validation dataset\n",
        "model_0.score(X=val_sentences,\n",
        "              y=val_labels_encoded)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7218323844829869"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dn22ZGrNR_d",
        "outputId": "6c56d2d9-8e92-4071-ba26-8b7ee197f565"
      },
      "source": [
        "# Make predictions using our baseline model\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 1, 3, ..., 4, 4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvB1odr6NlQ0",
        "outputId": "12b222f3-29e9-4d50-b2d6-0c5d01040304"
      },
      "source": [
        "val_labels_encoded"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 3, ..., 4, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qJQptveNzTa"
      },
      "source": [
        "Let's use helper function for calculating other evaluation metrics (precision, recall, f1): https://github.com/mrdbourke/tensorflow-deep-learning/blob/main/extras/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qKC9LvDOwc_",
        "outputId": "8094f763-86a6-41d5-fbb3-1a61e673e21b"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
        "\n",
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import calculate_results"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-26 01:17:14--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-26 01:17:14 (81.3 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew-hSrTdQ4AM",
        "outputId": "b58bcdc4-c9bc-4f5f-ad8c-8a6554e71ddf"
      },
      "source": [
        "# Calculate baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qXqiJduyPW2"
      },
      "source": [
        "### Model 1: Conv1D with token (word) embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjXZy5_vRJvW"
      },
      "source": [
        " #### Preparing our data (the text) for deep sequence models\n",
        "\n",
        "Our data is in text format right now. That's why we've got to create vectorization and embedding layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j00qwDD4S4y2"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHuN24x-TB3s",
        "outputId": "6331bb35-7332-486b-effa-116dde7ae1ac"
      },
      "source": [
        "# How long is each sentence on average? ( to get an idea of distribution of sentence length)\n",
        "sent_lens = [len(sentence.split()) for sentence in train_sentences]\n",
        "avg_sent_lens = np.mean(sent_lens)\n",
        "avg_sent_lens\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.338269273494777"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sa3qqb34UJCh"
      },
      "source": [
        "So, the average sentence length is 26 words (tokens).\n",
        "\n",
        "It is important because when we create batches of tensors, Tensorflow prefers them all to be in same shape.\n",
        "We calculate the average to pad the sequences to make them of same length and cut the extra large ones, such that every tensor has same dimensions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_TownYgQTXfD",
        "outputId": "93de89f2-830c-4bc5-8016-e629bd51daa8"
      },
      "source": [
        "# What's the distribution look like?\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(sent_lens, bins=20);"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4isccgTyAvz",
        "outputId": "50e5c8f4-d38c-4eac-cd45-9897800ee3d7"
      },
      "source": [
        "# How long of a sentence length covers 95% of examples?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6ZfFPaUy4nw"
      },
      "source": [
        "This implies that 95% of sentences are under 55 tokens in length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqzLBLTiytok",
        "outputId": "c752fa5c-091b-49a9-c642-78ca6edd02ad"
      },
      "source": [
        "# maximum sequence length in the training set\n",
        "max(sent_lens)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "296"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjhYoydEzJ-a",
        "outputId": "40d318dc-a8de-4578-d816-96b0c1d1967c"
      },
      "source": [
        "min(sent_lens)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnhF0-QBzN-V"
      },
      "source": [
        "#### Create word vectorizer layer\n",
        "\n",
        "We want to make a layer which maps our texts from words to numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7_suKyNJ4bU",
        "outputId": "8c6819da-2322-4931-c7a4-7588cde05b77"
      },
      "source": [
        "# total number of words\n",
        "words_count_list = [len(sentence.split()) for sentence in train_sentences]\n",
        "np.sum(words_count_list)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4741942"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4uylC8wzrrS"
      },
      "source": [
        "# How many words are in our vocab? ( taken from table 2 in paper)\n",
        "max_tokens = 68000  # most common 68000 unique words are allowed in vocab"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_-PH2KWnC0t"
      },
      "source": [
        "`max_tokens` = how many words in your dataset do you want to allow text vectorizer layer to turn into numbers?\n",
        "\n",
        "So, let's say vocab has 10000 words but we define `max_tokens` to be 5000. Then only most common 5000 words in vocab will be mapped to a number and the rest 5000 will be mapped to out of vocab token (unknown). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hondU_Ut02VK"
      },
      "source": [
        "# Create text vectorizer\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_tokens, # no. of words in vocab\n",
        "                                    output_sequence_length=output_seq_len) # desired output length of vectorized sequences\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmhOmCco1aBa"
      },
      "source": [
        "# adapt text vectorizer to the training sentences\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etSTklH4ijnn",
        "outputId": "8b153106-c569-4bf1-af82-168082ab8fb7"
      },
      "source": [
        "# test out text vectorizer on random sentences\n",
        "import random\n",
        "target_sentence = random.choice(train_sentences)\n",
        "print(f\"Text:\\n{target_sentence}\")\n",
        "print(f\"\\nLength of text: {len(target_sentence.split())}\")\n",
        "print(f\"\\nVectorized text: {text_vectorizer([target_sentence])}\")\n",
        "print(f\"\\nLength of vectorized text: {len(text_vectorizer([target_sentence])[0])}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text:\n",
            "in @ patients from the drug group , the stone was completely dissolved .\n",
            "\n",
            "Length of text: 14\n",
            "\n",
            "Vectorized text: [[    5    12    27     2   300    13     2  2855    10  3016 10387     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Length of vectorized text: 55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REqlwta_jBec",
        "outputId": "548d8bc6-5773-4856-bdf0-dbd1dcc7fc49"
      },
      "source": [
        " # How many words in our training vocab?\n",
        " rct_20k_text_vocab = text_vectorizer.get_vocabulary()\n",
        " print(f\"Number of words in vocab: {len(rct_20k_text_vocab)}\")\n",
        " print(f\"Most common words in the vocab: {rct_20k_text_vocab[:5]}\")\n",
        " print(f\"Least common words in the vocab: {rct_20k_text_vocab[-5:]}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 64841\n",
            "Most common words in the vocab: ['', '[UNK]', 'the', 'and', 'of']\n",
            "Least common words in the vocab: ['aainduced', 'aaigroup', 'aachener', 'aachen', 'aaacp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyuQ8QJ_mp-V",
        "outputId": "b3b7bd1a-c144-40e6-f87d-cfd47467a207"
      },
      "source": [
        "# get the config of our text vectorizer\n",
        "text_vectorizer.get_config()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_input_shape': (None,),\n",
              " 'dtype': 'string',\n",
              " 'idf_weights': None,\n",
              " 'max_tokens': 68000,\n",
              " 'name': 'text_vectorization',\n",
              " 'ngrams': None,\n",
              " 'output_mode': 'int',\n",
              " 'output_sequence_length': 55,\n",
              " 'pad_to_max_tokens': False,\n",
              " 'ragged': False,\n",
              " 'sparse': False,\n",
              " 'split': 'whitespace',\n",
              " 'standardize': 'lower_and_strip_punctuation',\n",
              " 'trainable': True,\n",
              " 'vocabulary': None}"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQb862p9pTx0"
      },
      "source": [
        "#### Create custom word embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROAuWEghsOU_"
      },
      "source": [
        "Text vectorizer has converted text into numbers. However, it doesn't necessarily capture relationship between those numbers. Let's use an embedding layer for that purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pl-4S8pzsMJp"
      },
      "source": [
        "# Create token embedding layer\n",
        "token_embed = layers.Embedding(input_dim=len(rct_20k_text_vocab), # length of vocab\n",
        "                               output_dim=128, # diff embedding sizes result in drastically diff number of parameters to be learned\n",
        "                               mask_zero=True, # use masking to handle variable sequence length\n",
        "                               name=\"token_embedding\") "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G3OWAxctnDp",
        "outputId": "63f72183-8ea7-4a1c-ea98-bf0b74a69d10"
      },
      "source": [
        "# Show example embedding\n",
        "print(f\"Sentence before vectorization:\\n{target_sentence}\\n\")\n",
        "vectorized_sentence = text_vectorizer([target_sentence])\n",
        "print(f\"Sentence after vectorization (before embedding):\\n {vectorized_sentence}\\n\")\n",
        "embedded_sentence = token_embed(vectorized_sentence)\n",
        "print(f\"Sentence after embedding:\\n {embedded_sentence}\\n\")\n",
        "print(f\"Embedded sentence shape: {embedded_sentence.shape}\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence before vectorization:\n",
            "in @ patients from the drug group , the stone was completely dissolved .\n",
            "\n",
            "Sentence after vectorization (before embedding):\n",
            " [[    5    12    27     2   300    13     2  2855    10  3016 10387     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0]]\n",
            "\n",
            "Sentence after embedding:\n",
            " [[[ 0.02829241 -0.04093079 -0.02775384 ...  0.01500003  0.04225096\n",
            "   -0.01904113]\n",
            "  [-0.00420902  0.0223053  -0.01436143 ... -0.02533544  0.02712259\n",
            "    0.01903334]\n",
            "  [ 0.0486279  -0.03149407  0.0356254  ...  0.04311044  0.02414585\n",
            "    0.02494422]\n",
            "  ...\n",
            "  [-0.03825574 -0.01649065  0.00500346 ...  0.02724483  0.00177784\n",
            "    0.04801438]\n",
            "  [-0.03825574 -0.01649065  0.00500346 ...  0.02724483  0.00177784\n",
            "    0.04801438]\n",
            "  [-0.03825574 -0.01649065  0.00500346 ...  0.02724483  0.00177784\n",
            "    0.04801438]]]\n",
            "\n",
            "Embedded sentence shape: (1, 55, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grjmyqu0uRSI"
      },
      "source": [
        "#### Creating datasets (making sure our data loads as fast as possible)\n",
        "\n",
        "We're going to setup our data to run as fast as possible with the tensorflow `tf.data` API.\n",
        "\n",
        "Resource: \n",
        "* https://www.tensorflow.org/guide/data_performance\n",
        "* https://www.tensorflow.org/guide/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5EnAPamvq_o",
        "outputId": "1f11f855-4c09-4235-d495-542f0b8d3087"
      },
      "source": [
        "# Turn our data into Tensorflow datasets\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences, train_labels_one_hot))\n",
        "valid_dataset = tf.data.Dataset.from_tensor_slices((val_sentences, val_labels_one_hot))\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_sentences, test_labels_one_hot))\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<TensorSliceDataset shapes: ((), (5,)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4MdEtigxSPJ",
        "outputId": "81a58b32-63f9-49ca-9036-011d6c47f13d"
      },
      "source": [
        "# Take the TensorSliceDataset's and turn them into prefetched datasets\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset = test_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "train_dataset"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns0BqpCtyHrd"
      },
      "source": [
        "We are not shuffling the data as the order of data in dataset is important for this sequence problem. We want our model to learn the sequence in our data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcPFG6x95g1C"
      },
      "source": [
        "#### Build a Conv1D model to fit on word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kW1e_gTzPjT"
      },
      "source": [
        "# Create 1D conv model to process sequences\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "text_vectors = text_vectorizer(inputs) #vectorize text inputs\n",
        "token_embeddings = token_embed(text_vectors) # create embedding\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(token_embeddings)\n",
        "x = layers.GlobalAveragePooling1D()(x)  # condense the output of feature vector from conv layer\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile\n",
        "model_1.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nLB9wkbY7ys",
        "outputId": "45ae45a2-2cb2-4355-8a6b-1c49852cf863"
      },
      "source": [
        "# get the model summary\n",
        "model_1.summary()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 55)               0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " token_embedding (Embedding)  (None, 55, 128)          8299648   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 55, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,340,997\n",
            "Trainable params: 8,340,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckw8WiysZd7u",
        "outputId": "d52a9c78-7ecf-4057-bf37-836573205f90"
      },
      "source": [
        "len(train_dataset)  # number of batches"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5627"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDufKe21ZiIi",
        "outputId": "792915ed-8d48-4582-cab2-bf50005ba3c5"
      },
      "source": [
        "# total number of samples\n",
        "len(train_dataset) * 32"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180064"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpHZLPpjZAIf",
        "outputId": "887d4519-4682-4c02-d2aa-bf5433624e52"
      },
      "source": [
        "# fit the model\n",
        "history_model_1 = model_1.fit(train_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)), # we only want our model to look at 10% of batches at every epoch\n",
        "                              epochs=3,\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 59s 103ms/step - loss: 0.9183 - accuracy: 0.6377 - val_loss: 0.6920 - val_accuracy: 0.7377\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 58s 103ms/step - loss: 0.6630 - accuracy: 0.7549 - val_loss: 0.6343 - val_accuracy: 0.7706\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 58s 102ms/step - loss: 0.6212 - accuracy: 0.7722 - val_loss: 0.5992 - val_accuracy: 0.7829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLI5AmBHaKO8",
        "outputId": "0580ce1d-a6fa-467b-ebf7-38375c086a86"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_1.evaluate(valid_dataset)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 5s 6ms/step - loss: 0.6021 - accuracy: 0.7839\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6021356582641602, 0.7838607430458069]"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nwOpiI1BbAeJ",
        "outputId": "4682173f-d858-4431-c151-1ae5b76553ce"
      },
      "source": [
        "# make predictions (our model predicts prediction probailities for each class)\n",
        "model_1_pred_probs = model_1.predict(valid_dataset)\n",
        "model_1_pred_probs, model_1_pred_probs.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[4.27264154e-01, 1.88418612e-01, 9.48695242e-02, 2.62621641e-01,\n",
              "         2.68261209e-02],\n",
              "        [4.10138428e-01, 3.14805597e-01, 1.18216155e-02, 2.56137520e-01,\n",
              "         7.09682982e-03],\n",
              "        [1.50945112e-01, 9.79710277e-03, 2.71499529e-03, 8.36500764e-01,\n",
              "         4.19948010e-05],\n",
              "        ...,\n",
              "        [5.64830634e-06, 8.98751314e-04, 1.12668471e-03, 2.77824415e-06,\n",
              "         9.97966170e-01],\n",
              "        [5.54772243e-02, 5.13569057e-01, 8.09422359e-02, 6.35865331e-02,\n",
              "         2.86424994e-01],\n",
              "        [2.28015810e-01, 5.76779544e-01, 5.49270213e-02, 6.05774187e-02,\n",
              "         7.97001347e-02]], dtype=float32), (30212, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QdxYKsBbPpf",
        "outputId": "3c73f794-7228-4734-c11b-ad11597aa262"
      },
      "source": [
        "# Convert pred probs to classes\n",
        "model_1_preds = tf.argmax(model_1_pred_probs, axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 0, 3, ..., 4, 1, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzZB_iRabeJT",
        "outputId": "e1d94eed-71f6-40c0-c232-9155f501e87d"
      },
      "source": [
        "# Calculate model_1 results\n",
        "model_1_results = calculate_results(val_labels_encoded,\n",
        "                                    model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.38607175956574,\n",
              " 'f1': 0.7813477934761195,\n",
              " 'precision': 0.7804616906577629,\n",
              " 'recall': 0.7838607175956573}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hTkp4Neblyg",
        "outputId": "c77167c2-c75f-4dbd-8bdd-01fae8e535a4"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm08vqDIbu5w"
      },
      "source": [
        "### Model 2: Feature Extraction with Pretrained token embeddings\n",
        "\n",
        "Now let's use pretrained word embeddings from Tensorflow hub: https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "The paper originally used Glove embeddings, however we'll be using USE pretrained word embeddings from Tensorflow hub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcdxRQA5c60C"
      },
      "source": [
        "# Download pretrained Tensorflow hub USE\n",
        "import tensorflow_hub as hub\n",
        "tf_hub_embedding_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                         trainable=False,\n",
        "                                         name=\"universal_sentence_encoder\")"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4zfOmX2esOL",
        "outputId": "11fbfa0d-175b-45a7-83aa-2133f583d5b2"
      },
      "source": [
        "# Test out the pretrained embedding on a random sentence\n",
        "random_train_sentence = random.choice(train_sentences)\n",
        "print(f\"Random Sentence:\\n {random_train_sentence}\")\n",
        "use_embedded_sentence = tf_hub_embedding_layer([random_train_sentence])\n",
        "print(f\"Sentence after embedding:\\n {use_embedded_sentence[0][:10]}\\n\")\n",
        "print(f\"Length of sentence embedding: {len(use_embedded_sentence[0])}\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Sentence:\n",
            " mifepristone in combination with ethacridine lactate may significantly improve the outcomes of second trimester pregnancy termination compared with ethacridine lactate alone , without increasing complications and side effects apart from nausea .\n",
            "Sentence after embedding:\n",
            " [ 0.01271546 -0.02111994 -0.06388303 -0.01375521  0.02986106 -0.061659\n",
            "  0.00196712 -0.05093328  0.06907311  0.0370948 ]\n",
            "\n",
            "Length of sentence embedding: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-27vzkJkfTXZ"
      },
      "source": [
        "#### Bulding and fitting an NLP feature extraction model using pretrained embeddings Tensorflow Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7nO84w6gJoH"
      },
      "source": [
        "# Define feature extractor model using TF Hub layer\n",
        "inputs = layers.Input(shape=[], dtype=tf.string)\n",
        "pretrained_embedding = tf_hub_embedding_layer(inputs) # tokenize text and create embedding\n",
        "x = layers.Dense(128, activation=\"relu\")(pretrained_embedding) # add a fully connected layer on top of the embedding\n",
        "# Note: you could add more layers here if you wanted to\n",
        "outputs = layers.Dense(5, activation=\"softmax\")(x) # create the output layer\n",
        "model_2 = tf.keras.Model(inputs=inputs,\n",
        "                        outputs=outputs,\n",
        "                         name=\"model_2_USE_feature_extractor\")\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu-8XsushKAS",
        "outputId": "4ae0b809-dd76-42d3-ff89-7fbeefdf0ecd"
      },
      "source": [
        "# Get a summary of the model\n",
        "model_2.summary()\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_USE_feature_extractor\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " universal_sentence_encoder   (None, 512)              256797824 \n",
            " (KerasLayer)                                                    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,864,133\n",
            "Trainable params: 66,309\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWvhku7jhW2W",
        "outputId": "fa60cdce-829e-4789-acee-8918313873cd"
      },
      "source": [
        "# Fit model_2 to data\n",
        "history_model_2 = model_2.fit(train_dataset,\n",
        "                              epochs=3,\n",
        "                              steps_per_epoch=int(0.1*len(train_dataset)),\n",
        "                              validation_data=valid_dataset,\n",
        "                              validation_steps=int(0.1*len(valid_dataset)))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 10s 14ms/step - loss: 0.9152 - accuracy: 0.6483 - val_loss: 0.7960 - val_accuracy: 0.6878\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.7684 - accuracy: 0.7015 - val_loss: 0.7537 - val_accuracy: 0.7055\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 7s 13ms/step - loss: 0.7522 - accuracy: 0.7114 - val_loss: 0.7377 - val_accuracy: 0.7108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9tH0Bq0k1Ya",
        "outputId": "4992f07a-db33-49ed-e91a-50664974b72e"
      },
      "source": [
        "# Evaluate on whole validation dataset\n",
        "model_2.evaluate(valid_dataset)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945/945 [==============================] - 10s 11ms/step - loss: 0.7411 - accuracy: 0.7131\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7411079406738281, 0.7131272554397583]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0W6Z-JBlHsm",
        "outputId": "7b2514f7-44f7-49f3-c9e9-b2a0a784951e"
      },
      "source": [
        "# Make predcitions with feature extraction model\n",
        "model_2_pred_probs = model_2.predict(valid_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.4351426e-01, 3.4093758e-01, 1.9383972e-03, 2.0509328e-01,\n",
              "        8.5164150e-03],\n",
              "       [3.5752693e-01, 5.0741291e-01, 3.7570533e-03, 1.2774581e-01,\n",
              "        3.5573100e-03],\n",
              "       [2.3613682e-01, 1.4078739e-01, 1.5261770e-02, 5.6418979e-01,\n",
              "        4.3624233e-02],\n",
              "       ...,\n",
              "       [1.7688605e-03, 6.0198004e-03, 5.0073389e-02, 9.0746081e-04,\n",
              "        9.4123054e-01],\n",
              "       [3.4054231e-03, 4.8480917e-02, 2.1666543e-01, 1.3002905e-03,\n",
              "        7.3014790e-01],\n",
              "       [1.9020347e-01, 2.5467929e-01, 4.9172160e-01, 7.0162332e-03,\n",
              "        5.6379423e-02]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsFGjpmJlQMq",
        "outputId": "5fb3e305-3e90-43ac-879b-0d1c0434071a"
      },
      "source": [
        "# Convert the prediction probailities to labels\n",
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([0, 1, 3, ..., 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyKjzKm7lc_y"
      },
      "source": [
        "# calculate model_2 results\n",
        "model_2_results = calculate_results(val_labels_encoded,\n",
        "                                    model_2_preds)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVhB9ob9loBr",
        "outputId": "aeae7536-8462-4aa0-c1b6-3e731cd9b9fe"
      },
      "source": [
        "model_2_results"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 71.31272342115716,\n",
              " 'f1': 0.7102334536050207,\n",
              " 'precision': 0.7133128111982996,\n",
              " 'recall': 0.7131272342115715}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2Vgl0bzlpoM",
        "outputId": "35134150-017c-472a-cfe8-a470869c009e"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 72.1832384482987,\n",
              " 'f1': 0.6989250353450294,\n",
              " 'precision': 0.7186466952323352,\n",
              " 'recall': 0.7218323844829869}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YawBmHDVltmm"
      },
      "source": [
        "### Model 3: Conv1D with character embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEmDFGI09VQQ"
      },
      "source": [
        "#### Preparing data for character-level tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOR3O9-Lm0p-",
        "outputId": "1f8d1cd9-523a-4fb2-d7da-cc07f701f731"
      },
      "source": [
        "train_sentences[:3]"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['to investigate the efficacy of @ weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at @ weeks in older adults with moderate to severe knee osteoarthritis ( oa ) .',\n",
              " 'a total of @ patients with primary knee oa were randomized @:@ ; @ received @ mg/day of prednisolone and @ received placebo for @ weeks .',\n",
              " 'outcome measures included pain reduction and improvement in function scores and systemic inflammation markers .']"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "tlhAHiR8m2va",
        "outputId": "5d6a110a-c896-4e40-8eb2-1cb5d1048551"
      },
      "source": [
        "# make function to split sentences into characters\n",
        "def split_chars(text):\n",
        "  return \" \".join(list(text))\n",
        "\n",
        "# Text splitting non-character-level sequence into characters\n",
        "split_chars(random_train_sentence)"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'m i f e p r i s t o n e   i n   c o m b i n a t i o n   w i t h   e t h a c r i d i n e   l a c t a t e   m a y   s i g n i f i c a n t l y   i m p r o v e   t h e   o u t c o m e s   o f   s e c o n d   t r i m e s t e r   p r e g n a n c y   t e r m i n a t i o n   c o m p a r e d   w i t h   e t h a c r i d i n e   l a c t a t e   a l o n e   ,   w i t h o u t   i n c r e a s i n g   c o m p l i c a t i o n s   a n d   s i d e   e f f e c t s   a p a r t   f r o m   n a u s e a   .'"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-VzM7SwnRhp"
      },
      "source": [
        "# split sequence-level splits into character-level data splits\n",
        "train_chars = [split_chars(sentence) for sentence in train_sentences]\n",
        "val_chars =[split_chars(sentence) for sentence in val_sentences]\n",
        "test_chars =[split_chars(sentence) for sentence in test_sentences]\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfEXX5S5oINc",
        "outputId": "20cc9724-a095-4142-f417-258e634feb6f"
      },
      "source": [
        "# what's the average character length?\n",
        "char_lens = [len(sentence.split()) for sentence in train_chars]\n",
        "mean_char_lens = np.mean(char_lens)\n",
        "mean_char_lens"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124.02798822483892"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yemd4ktnqLqH",
        "outputId": "58fa1aee-e68f-490e-d5e3-6cf456a9cf1f"
      },
      "source": [
        "char_lens[:10]"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[233, 111, 97, 52, 175, 119, 132, 110, 145, 44]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "H5HzEAbjp9JB",
        "outputId": "ae902402-52e4-4bd1-a916-19631bc669c6"
      },
      "source": [
        "# check the distribution of our sequences at a character level\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(char_lens, bins=20);"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEr-_ujWqX22",
        "outputId": "a77a965a-d1f8-4eb2-a029-0069acde2429"
      },
      "source": [
        "# find what character length covers 95% of sequences\n",
        "output_seq_char_len = int(np.percentile(char_lens, 95))\n",
        "output_seq_char_len"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "239"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCFo2Ix0mI3C"
      },
      "source": [
        "#### Creating a character-level tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hVBheU3qqvX1",
        "outputId": "cf215e36-470d-4b15-c54b-a31ac5991150"
      },
      "source": [
        "# get all keyboard characters\n",
        "import string\n",
        "alphabet = string.ascii_lowercase + string.digits +string.punctuation\n",
        "alphabet"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'abcdefghijklmnopqrstuvwxyz0123456789!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wf1cJBlEWkN",
        "outputId": "7c38893a-7ca1-4f0d-c60d-0e472386e513"
      },
      "source": [
        "NUM_CHAR_TOKENS = len(alphabet) +2 # add 2 for space and OOV token (OOV = out of vocab)\n",
        "NUM_CHAR_TOKENS"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "70"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVvAPeh3rb2r"
      },
      "source": [
        "# Create char-level token vectorizer instance\n",
        "char_vectorizer = TextVectorization(max_tokens=NUM_CHAR_TOKENS,\n",
        "                                    output_sequence_length=output_seq_char_len,\n",
        "                                    # standardize=None,\n",
        "                                    name=\"char_vectorizer\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGfUHeYNsGg9"
      },
      "source": [
        "# Adapt character vectorizer to training character \n",
        "char_vectorizer.adapt(train_chars)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_cU_0e_sSJK",
        "outputId": "b1aa9b6c-f2c9-4f6c-d069-82dffda9fc9f"
      },
      "source": [
        "# check character vocabs stats\n",
        "char_vocab = char_vectorizer.get_vocabulary()\n",
        "print(f\"Number of different characters in character vocab: {len(char_vocab)}\")\n",
        "print(f\"5 most common characters; {char_vocab[:5]}\")\n",
        "print(f\"5 least common characters: {char_vocab[-5:]}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different characters in character vocab: 28\n",
            "5 most common characters; ['', '[UNK]', 'e', 't', 'i']\n",
            "5 least common characters: ['k', 'x', 'z', 'q', 'j']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zs_bzYjIJvh",
        "outputId": "56750280-216c-4547-ea10-d53745f05cb4"
      },
      "source": [
        "char_vectorizer.vocabulary_size()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9aC6_XVtEsa",
        "outputId": "2466a67d-8032-4624-98c5-db2adaf2a9e6"
      },
      "source": [
        "# Test out haracter vectorizer\n",
        "random_train_chars = random.choice(train_chars)\n",
        "print(f\"Charified text:\\n {random_train_chars}\")\n",
        "print(f\"\\nLength of random_train_chars: {len(random_train_chars.split())}\")\n",
        "vectorized_chars = char_vectorizer([random_train_chars])\n",
        "print(f\"\\nVectorized chars:\\n {vectorized_chars}\")\n",
        "print(f\"\\nLength of vectorized chars: {len(vectorized_chars[0])}\")"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text:\n",
            " p a t i e n t s   u n d e r w e n t   q u e r l e u - m o r r o w   t y p e   b @   o r   c @   r a d i c a l   h y s t e r e c t o m y   .\n",
            "\n",
            "Length of random_train_chars: 61\n",
            "\n",
            "Vectorized chars:\n",
            " [[14  5  3  4  2  6  3  9 16  6 10  2  8 20  2  6  3 26 16  2  8 12  2 16\n",
            "  15  7  8  8  7 20  3 19 14  2 22  7  8 11  8  5 10  4 11  5 12 13 19  9\n",
            "   3  2  8  2 11  3  7 15 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]]\n",
            "\n",
            "Length of vectorized chars: 239\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4116Wv_0n5G"
      },
      "source": [
        "#### Creating a character-level embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjExd7tR04nq"
      },
      "source": [
        "# Create char embedding layer\n",
        "char_embed = layers.Embedding(input_dim=len(char_vocab), # number of different characters\n",
        "                              output_dim=25, # this is the size of the char embedding in the paper\n",
        "                              mask_zero=True,\n",
        "                              name=\"char_embed\")"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpnwAukH1xGR",
        "outputId": "abcf5daa-33f6-4212-d4b0-b560db26630e"
      },
      "source": [
        "# Test our character embedding layer\n",
        "print(f\"Charified text: \\n {random_train_chars}\\n\")\n",
        "char_embed_example = char_embed(char_vectorizer([random_train_chars]))\n",
        "print(f\"Embedded chars (after vectorization and embedding):\\n {char_embed_example}\\n\")\n",
        "print(f\"Character Embedding shape: {char_embed_example.shape}\")"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Charified text: \n",
            " p a t i e n t s   u n d e r w e n t   q u e r l e u - m o r r o w   t y p e   b @   o r   c @   r a d i c a l   h y s t e r e c t o m y   .\n",
            "\n",
            "Embedded chars (after vectorization and embedding):\n",
            " [[[-0.02651849  0.01152896 -0.00313633 ... -0.00622438 -0.00463691\n",
            "   -0.01265049]\n",
            "  [ 0.00280971  0.0134583  -0.00543315 ...  0.01013011 -0.02915632\n",
            "    0.02991359]\n",
            "  [-0.04871669  0.01340515 -0.00270136 ...  0.02632791  0.01118189\n",
            "   -0.03922912]\n",
            "  ...\n",
            "  [-0.03704701 -0.03390922  0.04064589 ... -0.00891387  0.03459607\n",
            "    0.0489949 ]\n",
            "  [-0.03704701 -0.03390922  0.04064589 ... -0.00891387  0.03459607\n",
            "    0.0489949 ]\n",
            "  [-0.03704701 -0.03390922  0.04064589 ... -0.00891387  0.03459607\n",
            "    0.0489949 ]]]\n",
            "\n",
            "Character Embedding shape: (1, 239, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SMLvdgm4Nbp"
      },
      "source": [
        "#### Create char level datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC9Iq2268COi"
      },
      "source": [
        "train_char_dataset = tf.data.Dataset.from_tensor_slices((train_chars, train_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "val_char_dataset = tf.data.Dataset.from_tensor_slices((val_chars, val_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)\n",
        "test_char_dataset = tf.data.Dataset.from_tensor_slices((test_chars, test_labels_one_hot)).batch(32).prefetch(tf.data.AUTOTUNE)"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnkHAlxG8stc",
        "outputId": "6a1d7737-ec4e-4952-8414-2373d6f2165c"
      },
      "source": [
        "train_char_dataset"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: ((None,), (None, 5)), types: (tf.string, tf.float64)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVOZ6EPN2hZd"
      },
      "source": [
        "#### Building a Conv1D model to fit on character embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Alo4iZFP3MrJ"
      },
      "source": [
        "# Make Conv1D on chars only\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "char_vectors = char_vectorizer(inputs)\n",
        "char_embeddings = char_embed(char_vectors)\n",
        "x = layers.Conv1D(64, kernel_size=5, padding=\"same\", activation=\"relu\")(char_embeddings)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "model_3 = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=\"model_3_conv1d_char_embeddings\")\n",
        "\n",
        "# Compile the model\n",
        "model_3.compile(loss=\"categorical_crossentropy\",\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ta5IxVV4J3B",
        "outputId": "e98f0ba5-84b9-4165-cb5f-6bc8fac0391a"
      },
      "source": [
        "# get the model summary\n",
        "model_3.summary()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_conv1d_char_embeddings\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " char_vectorizer (TextVector  (None, 239)              0         \n",
            " ization)                                                        \n",
            "                                                                 \n",
            " char_embed (Embedding)      (None, 239, 25)           700       \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 239, 64)           8064      \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 64)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,089\n",
            "Trainable params: 9,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84apCMvT-fSu",
        "outputId": "a58ade15-5037-444a-ce0b-1ccc29739cb5"
      },
      "source": [
        "# Fit the model on chars only\n",
        "model_3_history = model_3.fit(train_char_dataset,\n",
        "                              steps_per_epoch=int(0.1*len(train_char_dataset)),\n",
        "                              epochs=3,\n",
        "                              validation_data=val_char_dataset,\n",
        "                              validation_steps=int(0.1*len(val_char_dataset)))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "562/562 [==============================] - 29s 49ms/step - loss: 1.2443 - accuracy: 0.4814 - val_loss: 1.1069 - val_accuracy: 0.5439\n",
            "Epoch 2/3\n",
            "562/562 [==============================] - 30s 53ms/step - loss: 1.0809 - accuracy: 0.5582 - val_loss: 1.0080 - val_accuracy: 0.5938\n",
            "Epoch 3/3\n",
            "562/562 [==============================] - 32s 57ms/step - loss: 0.9947 - accuracy: 0.6076 - val_loss: 0.9316 - val_accuracy: 0.6370\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vFLfUmN_CUC",
        "outputId": "97552451-73d2-48a8-e118-40537d303c91"
      },
      "source": [
        "# Make predictions with character model only\n",
        "model_3_pred_probs = model_3.predict(val_char_dataset)\n",
        "model_3_pred_probs"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15115614, 0.38340878, 0.07200373, 0.3586171 , 0.03481421],\n",
              "       [0.1805461 , 0.3095684 , 0.04038429, 0.43860114, 0.03089999],\n",
              "       [0.2065555 , 0.10115051, 0.22826818, 0.42009744, 0.04392836],\n",
              "       ...,\n",
              "       [0.04766627, 0.08353814, 0.23578906, 0.04867817, 0.5843284 ],\n",
              "       [0.05075679, 0.1849281 , 0.39402103, 0.1359862 , 0.23430784],\n",
              "       [0.43797934, 0.326872  , 0.10314243, 0.09577801, 0.0362282 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rb4CCJOAE-j",
        "outputId": "7758272b-9b04-40ff-daab-f4897102dab4"
      },
      "source": [
        "# Convert pred probabilities to class labels\n",
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(30212,), dtype=int64, numpy=array([1, 3, 3, ..., 4, 2, 0])>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgqA47i_AUEc"
      },
      "source": [
        "# Calculate results for Conv1D model chars only\n",
        "model_3_results = calculate_results(y_true=val_labels_encoded,\n",
        "                                    y_pred=model_3_preds)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArOfff2IAhec",
        "outputId": "36390d95-1bd7-4a92-f040-a4ce9d6cffdc"
      },
      "source": [
        "model_3_results"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 62.756520587845884,\n",
              " 'f1': 0.618172552042671,\n",
              " 'precision': 0.6319298163861264,\n",
              " 'recall': 0.6275652058784589}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk3blR-kAjIo",
        "outputId": "eda565ed-8b99-4301-a7b1-a12d6479ac91"
      },
      "source": [
        "baseline_results, model_1_results, model_2_results"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy': 72.1832384482987,\n",
              "  'f1': 0.6989250353450294,\n",
              "  'precision': 0.7186466952323352,\n",
              "  'recall': 0.7218323844829869},\n",
              " {'accuracy': 78.38607175956574,\n",
              "  'f1': 0.7813477934761195,\n",
              "  'precision': 0.7804616906577629,\n",
              "  'recall': 0.7838607175956573},\n",
              " {'accuracy': 71.31272342115716,\n",
              "  'f1': 0.7102334536050207,\n",
              "  'precision': 0.7133128111982996,\n",
              "  'recall': 0.7131272342115715})"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJKjnX2TAtg9"
      },
      "source": [
        "So, `model_3` is our worst performing model yet. This shows that not all experiments lead to better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLj_LbnBAluF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}